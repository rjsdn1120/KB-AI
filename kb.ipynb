{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71807de8",
   "metadata": {},
   "source": [
    "# kb-albert 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54eac65a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjsdn/.conda/envs/kb_albert/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1641: FutureWarning: Calling KbAlbertCharTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n",
      "The class this function is called from is 'KbAlbertCharTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rjsdn/kb-albert-char/examples/vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/rjsdn/kb-albert-char/examples/pytorch_model.bin were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.weight', 'predictions.dense.bias', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'sop_classifier.classifier.bias', 'predictions.decoder.weight', 'predictions.bias', 'predictions.dense.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at /home/rjsdn/kb-albert-char/examples/pytorch_model.bin and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0,os.path.abspath('./kb-albert-char/examples'))\n",
    "\n",
    "from transformers import AlbertForSequenceClassification\n",
    "from tokenization_kbalbert import KbAlbertCharTokenizer\n",
    "\n",
    "kb_albert_model_path = '/home/rjsdn/kb-albert-char/examples/pytorch_model.bin'\n",
    "vocab_path='/home/rjsdn/kb-albert-char/examples/vocab.txt'\n",
    "config_path='/home/rjsdn/kb-albert-char/examples/config.json'\n",
    "\n",
    "\n",
    "tokenizer = KbAlbertCharTokenizer.from_pretrained(vocab_path)\n",
    "model = AlbertForSequenceClassification.from_pretrained(kb_albert_model_path,config=config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e1d40",
   "metadata": {},
   "source": [
    "# 데이터 불러오고 데이터 어떤지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfcffc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  [Web발신] 국내 우한폐렴 급속도확산 감염자및 접촉차 신분정보 확인하기 news....\n",
      "1         [Web발신] 코로나 전염병환자 휴게소에서 수많은 사람과 접촉 http://\n",
      "2  [Web발신] [질병관리청] 8/5 코로나19 백신 예약 인증 본인확인 https:...\n",
      "3            OO저축은행에서 대출받으시면 1시간 이내에 처리될 수 있도록 하겠습니다\n",
      "4               저희는 이미 확정금리로 나왔습니다. 무조건 대출 진행 가능합니다.\n",
      "                                                text\n",
      "0                         퇴직연금 계좌정보 거래에서 출력할 수 있습니다.\n",
      "1  입출금 문자알림 서비스는 하나원큐, 영업점, 인터넷뱅킹, 폰뱅킹에서 신청할 수 있습니다.\n",
      "2  주거래 손님이라 함은 개별 손님 기준 우대등급 Family 이상 또는 결제성과 상품...\n",
      "3  급여이체는 매월 건당 50만원 이상의 급여성 자금이 본인 명의의 입출금이 자유로운 ...\n",
      "4               금융거래한도계좌는 1일 출금 및 이체한도가 제한되는 계좌 입니다.\n",
      "cnt0 379    cnt1 379\n",
      "                                                text\n",
      "0  [Web발신] [질병관리청] 코로나19 백신 디지털 예방접종증명서 발급 및 저장 본...\n",
      "1  [국외발신] [아마존닷컴]KRW 원, 해외결제 본인 요청 아닐경우 소비자 문의: 0...\n",
      "2  [국외발신] 고객님 신청하신 다이슨 디지털 슬림 플로피 OOO원 완료. 문의: (전...\n",
      "3  [Web발신] 로젠택배 고객님의 소포가 반송중 파손되었습니다. 배송상황을 확인하세요...\n",
      "4  고객님 쿠팡맨 김OO이라고 합니다. 제가 오늘 새벽에 배송중 다쳐서 입원하는 바람에...\n",
      "                                                text\n",
      "0     단, 온라인 전용펀드인 경우 2014년 5월 23일부터 변경되어 최저 1만원입니다.\n",
      "1        단, 장기주식형 3년기간 미충족 계좌는 일부환매 및 일반과세 전환 불가합니다.\n",
      "2  예금담보대출을 받은 경우 질권설정이 되어 있으므로 인터넷뱅킹에서 펀드 해지가 불가합니다.\n",
      "3  신분증, 통장, 도장(서명시 미지참) 지참하셔서 영업점 방문하셔서 해지 신청 해야 ...\n",
      "4  인터넷뱅킹에서 펀드 가입했을 경우 통장이 없기 때문에 신분증만 지참하셔서 영업점 방...\n",
      "cnt0 50    cnt1 50\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "class load_data(Dataset):\n",
    "    def __init__(self,tokenizer,is_train=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        file = 'test'\n",
    "        if is_train:\n",
    "            file = 'data'\n",
    "        df = pd.read_excel('data/'+file+'O.xlsx',names=['text'],usecols=[0],engine='openpyxl')\n",
    "        df = df.dropna(axis=0)\n",
    "        print(df.head())\n",
    "        self.data_list=[]\n",
    "        cnt0=0;cnt1=0\n",
    "        for i in range(len(df)):\n",
    "            x = df.iloc[i]\n",
    "            text=x['text']\n",
    "            cnt1+=1\n",
    "            try:\n",
    "                self.data_list.append((self.tokenizer(text,return_tensors='pt'),torch.tensor([1])))\n",
    "            except ValueError as e:\n",
    "                print(text)\n",
    "        l = len(df)\n",
    "        \n",
    "        df = pd.read_excel('data/'+file+'X.xlsx',names=['text'],usecols=[0],engine='openpyxl')\n",
    "        df = df.dropna(axis=0)\n",
    "        print(df.head())\n",
    "        for i in range(len(df)):\n",
    "            if i >= l and is_train: break\n",
    "            x = df.iloc[i]\n",
    "            text=x['text']\n",
    "            cnt0+=1\n",
    "            self.data_list.append((self.tokenizer(text,return_tensors='pt'),torch.tensor([0])))\n",
    "        print('cnt0',cnt0,'   cnt1',cnt1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return {\n",
    "            'text' : self.data_list[index][0],\n",
    "            'label' : self.data_list[index][1],\n",
    "        }       \n",
    "        \n",
    "train_load = load_data(tokenizer)\n",
    "train_data = DataLoader(train_load,batch_size=1,shuffle=True)\n",
    "\n",
    "test_load = load_data(tokenizer,is_train=0)\n",
    "test_data = DataLoader(test_load,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776861ba",
   "metadata": {},
   "source": [
    "# 학습하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "916fdb43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7934252023696899\n",
      "51.312382727861404\n",
      "79.68045045807958\n",
      "95.01730194874108\n",
      "106.88190414197743\n",
      "126.34270748123527\n",
      "139.26466165157035\n",
      "163.51361581869423\n",
      "epoch 1 | loss 0.229885818\n",
      "0.03919901326298714\n",
      "11.904204980004579\n",
      "28.429046508390456\n",
      "32.35019061062485\n",
      "45.286034518736415\n",
      "57.95830840046983\n",
      "64.52525698544923\n",
      "78.00800326059107\n",
      "epoch 2 | loss 0.109515079\n",
      "0.0037011471576988697\n",
      "6.8683521235361695\n",
      "8.61316395981703\n",
      "17.343342120642774\n",
      "18.200238104211167\n",
      "18.646998278447427\n",
      "19.315622966561932\n",
      "20.816924350627232\n",
      "epoch 3 | loss 0.027700304\n",
      "0.002689674962311983\n",
      "0.23566219312488101\n",
      "0.4981714768218808\n",
      "11.021333179000067\n",
      "15.687942619581008\n",
      "16.43184753303649\n",
      "19.07899022276979\n",
      "19.34729760402115\n",
      "epoch 4 | loss 0.025616710\n",
      "0.00032062159152701497\n",
      "0.17290140996919945\n",
      "0.24496536335209385\n",
      "6.875898115482414\n",
      "20.94645399277215\n",
      "23.288248249155004\n",
      "24.262002105271677\n",
      "24.528132702893345\n",
      "epoch 5 | loss 0.032571918\n",
      "0.006448413711041212\n",
      "0.11891170984017663\n",
      "0.2159039078251226\n",
      "0.5942306970682694\n",
      "0.9271123089711182\n",
      "1.8284593530916027\n",
      "2.240661238654866\n",
      "2.334730558712181\n",
      "epoch 6 | loss 0.003103625\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(),lr=0.0001/3)\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "epochs = 15\n",
    "mode=model.to(device)\n",
    "loss_list=[]\n",
    "cnt=0\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    avg_loss=0\n",
    "    cnt=0\n",
    "    for i in train_data:\n",
    "        # print(i['x'],i['y'])\n",
    "        optim.zero_grad()\n",
    "        x=i['text']\n",
    "        y=i['label']\n",
    "        for j in x:\n",
    "            x[j]=x[j].squeeze(0).to(device)\n",
    "        y=y.squeeze(0).to(device)\n",
    "        #break\n",
    "        po_len = len(x['input_ids'][0])\n",
    "        if po_len >512: continue\n",
    "        out = model(**x,labels=y)\n",
    "        \n",
    "            \n",
    "        loss = criterion(out.logits,y)\n",
    "        avg_loss += float(loss.item())\n",
    "        loss.backward(retain_graph=True)\n",
    "        optim.step()\n",
    "        if cnt%100 == 0 :\n",
    "            print(avg_loss)\n",
    "        cnt+=1\n",
    "    tmp_loss=avg_loss/cnt\n",
    "    loss_list.append(tmp_loss)\n",
    "    print('epoch {:1d} | loss {:.9f}'.format(epoch+1,tmp_loss))\n",
    "    if tmp_loss < 0.01: break\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76905020",
   "metadata": {},
   "source": [
    "# loss 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6785e7ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "xv = [i for i in range(1,len(loss_list)+1)]\n",
    "yv = loss_list\n",
    "\n",
    "plt.plot(xv,yv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233717c1",
   "metadata": {},
   "source": [
    "# 모델 성능 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2440328e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "y_true=[];y_pred=[]\n",
    "model.eval()\n",
    "test_loss=0\n",
    "with torch.no_grad():\n",
    "    avg_loss=0\n",
    "    cnt=0\n",
    "    ans=0\n",
    "    for i in test_data:\n",
    "        # print(i['x'],i['y'])\n",
    "        optim.zero_grad()\n",
    "        x=i['text']\n",
    "        y=i['label']\n",
    "        for j in x:\n",
    "            x[j]=x[j].squeeze(0).to(device)\n",
    "        y=y.squeeze(0).to(device)\n",
    "        #break\n",
    "        po_len = len(x['input_ids'][0])\n",
    "        if po_len >512: continue\n",
    "        out = model(**x,labels=y)\n",
    "        loss = criterion(out.logits,y)\n",
    "        avg_loss += float(loss.item())\n",
    "        pred = torch.argmax(out.logits).item()\n",
    "        cnt+=1\n",
    "        \n",
    "        y_true.append(y.item())\n",
    "        y_pred.append(pred)\n",
    "    test_loss=avg_loss/cnt\n",
    "\n",
    "print('test done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b160d",
   "metadata": {},
   "source": [
    "# loss, 정확도, f1 score, confusion matrix 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1432681a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.313611042625198\n",
      "test acc:94.000000000\n",
      "f1 score:0.938775510\n",
      "[[48  2]\n",
      " [ 4 46]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "print('test loss:', test_loss)\n",
    "print('test acc:{:.9f}'.format(accuracy_score(y_true,y_pred)*100))\n",
    "print('f1 score:{:.9f}'.format(f1_score(y_true,y_pred)))\n",
    "print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ec7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not s.isfile('./pino.pth'):\n",
    "    torch.save(model.state_dict(),'./pino.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97eeb485",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a42e32c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking arugment for argument index in method wrapper_index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-243efbef4c7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/kb_albert/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/kb_albert/lib/python3.6/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         )\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/kb_albert/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/kb_albert/lib/python3.6/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 720\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         )\n\u001b[1;32m    722\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m~/.conda/envs/kb_albert/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/kb_albert/lib/python3.6/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/kb_albert/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/kb_albert/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/kb_albert/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking arugment for argument index in method wrapper_index_select)"
     ]
    }
   ],
   "source": [
    "label_dict = {0:'피싱 x',1:'피싱 o'}\n",
    "test = [\n",
    "    '인터넷/스마트뱅킹으로 대출 진행 시 우리은행 전자뱅킹 보안매체(보안카드, OTP)와 인증서가 필요합니다.',\n",
    "    '보안매체가 없는 경우 신분증 지참 후 가까운 우리은행 영업점을 내점하여 보안매체 발급 해 주시거나,',\n",
    "    '결재대상목록에는 업무구분 없이 모든 승인요청 자료를 한꺼번에 조회할 수 있으며, 업무구분별로 구분하여 조회할 수도 있습니다.',\n",
    "    '최소 가입금액은 개인, 법인 1만원 이상입니다.',\n",
    "    '가까운 영업점 방문하여 상담 후 신청해주시거나, 모바일웹(hppt://m.wooribank.com) 또는 우리WON뱅킹을 통해 우리WON하는직장인대출 ‘사전한도/금리조회’ 메뉴를 통해 예상한도와 예상금리 조회 후 신청 가능합니다.',\n",
    "    '사장님께서 혹시 안쓰시는 계좌가 있으시면 저희가 월 400에서 450만원까지 선지급 해드리고 임대하고있어서 연락 드렸습니다',\n",
    "    '이번 사건은 대형 금융범죄입니다. 피해자가 200명이 넘고 10명 이상이 범죄에 가담하였습니다. 그 중 xxx씨께서 이 사건에 연루된것입니다.',\n",
    "    '통장번호와 통장 비밀번호, 신용카드 비밀번호 보내줘. 또 신분증도 찍어보내줘.',\n",
    "    '[Web발신] [질병관리청] 코로나19 백신 디지털 예방접종증명서 발급 및 저장 본인확인 httpsL//ya.mba/3Py83',\n",
    "    '갑자기 큰 돈을 찾는다고 하면 은행 직원이 의심할수도 있으니 보증금이라고 하세요'\n",
    "]\n",
    "\n",
    "for text in test:\n",
    "    tok = tokenizer(text,return_tensors='pt')\n",
    "    tok.to(device)\n",
    "    out = model(**tok)\n",
    "    pred = torch.argmax(out.logits).item()\n",
    "    print(label_dict[pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ffaadf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인터넷/스마트뱅킹으로 대출 진행 시 우리은행 전자뱅킹 보안매체(보안카드, OTP)와 인증서가 필요합니다.\n",
      "보안매체가 없는 경우 신분증 지참 후 가까운 우리은행 영업점을 내점하여 보안매체 발급 해 주시거나,\n",
      "결재대상목록에는 업무구분 없이 모든 승인요청 자료를 한꺼번에 조회할 수 있으며, 업무구분별로 구분하여 조회할 수도 있습니다.\n",
      "최소 가입금액은 개인, 법인 1만원 이상입니다.\n",
      "가까운 영업점 방문하여 상담 후 신청해주시거나, 모바일웹(hppt://m.wooribank.com) 또는 우리WON뱅킹을 통해 우리WON하는직장인대출 ‘사전한도/금리조회’ 메뉴를 통해 예상한도와 예상금리 조회 후 신청 가능합니다.\n",
      "사장님께서 혹시 안쓰시는 계좌가 있으시면 저희가 월 400에서 450만원까지 선지급 해드리고 임대하고있어서 연락 드렸습니다\n",
      "이번 사건은 대형 금융범죄입니다. 피해자가 200명이 넘고 10명 이상이 범죄에 가담하였습니다. 그 중 xxx씨께서 이 사건에 연루된것입니다.\n",
      "통장번호와 통장 비밀번호, 신용카드 비밀번호 보내줘. 또 신분증도 찍어보내줘.\n",
      "[Web발신] [질병관리청] 코로나19 백신 디지털 예방접종증명서 발급 및 저장 본인확인 httpsL//ya.mba/3Py83\n",
      "갑자기 큰 돈을 찾는다고 하면 은행 직원이 의심할수도 있으니 보증금이라고 하세요\n"
     ]
    }
   ],
   "source": [
    "for i in test:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d563a04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/rjsdn/kb-albert-char/examples/pytorch_model.bin were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.weight', 'predictions.dense.bias', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'sop_classifier.classifier.bias', 'predictions.decoder.weight', 'predictions.bias', 'predictions.dense.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at /home/rjsdn/kb-albert-char/examples/pytorch_model.bin and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피싱 o SequenceClassifierOutput(loss=None, logits=tensor([[-4.1911,  3.7570]], device='cuda:0', grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "newModel = AlbertForSequenceClassification.from_pretrained(kb_albert_model_path,config=config_path)\n",
    "newModel.load_state_dict(torch.load('./pino.pth'))\n",
    "newModel.to(device)\n",
    "newModel.eval()\n",
    "\n",
    "\n",
    "text = r'바이든 \"기시다 일본 총리 선출 축하…미일동맹은 안보 초석\"(종합)'\n",
    "tok = tokenizer(text,return_tensors='pt')\n",
    "tok.to(device)\n",
    "out = newModel(**tok)\n",
    "pred = torch.argmax(out.logits).item()\n",
    "print(label_dict[pred],out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
